# Remote Laboratory - PLC Data Acquisition System

## Overview

> ‚ö†Ô∏è **UFG TCC adaptation:** This repository extends the public work available at [github.com/RodSalg/remote-laboratory](https://github.com/RodSalg/remote-laboratory).  
> The entire codebase, folder naming and original scripts remain credited to the authors of that project; the changes documented here are exclusive to the capstone requirements at Universidade Federal de Goi√°s (UFG).

---

## Adaptations for the TCC project

- `lab-manager/readfiles.py`: CLI helper that scans every `.csv` located in the project root and prints each file as a formatted text table (normalizes column sizes, pads spacing, and keeps headers aligned). Run `python lab-manager/readfiles.py` to inspect collected datasets directly from the terminal.

---

## Remote Laboratory

The **Remote Laboratory** project provides a robust and automated system for **collecting**, **saving**, and **organizing** data from a Siemens PLC via the Snap7 communication protocol.  
The collected data is processed in real time, stored both in text/CSV files, and inserted into a structured **MySQL database** for further analysis.

The system is designed to facilitate experiments in mechatronics and automation laboratories, especially for pattern detection based on pulse trains.

This fork customizes configuration, documentation and helper scripts for the UFG capstone without altering the original ownership of the core solution.

---

## Features

- üõ†Ô∏è Real-time communication with Siemens PLC (S7 family) using **Snap7**.
- üíÑ Local storage of pulse trains in **.txt** and **.csv** formats.
- üßë‚Äçüß¨ Automated calculation of **pulse train steps**.
- üèõÔ∏è Insertions and retrievals from a **MySQL database** (`cae_dr` schema).
- üìà Support for experiment tracking and pulse pattern management.
- üßπ Automatic versioning of exported files (avoiding data overwriting).
- üßπ Easy integration with future modules (e.g., machine learning, pattern recognition).

---

## Project Structure

```
REMOTE-LABORATORY/
‚îú‚îÄ‚îÄ __pycache__/              # Python cache files (ignored)
‚îú‚îÄ‚îÄ data/                     # Generated text and CSV files
‚îú‚îÄ‚îÄ database-scripts/         # SQL scripts (CREATE statements) for database structure
‚îÇ    ‚îú‚îÄ‚îÄ cae_dr_dadoscoletados2.sql
‚îÇ    ‚îú‚îÄ‚îÄ patterns_from_professor.sql
‚îÇ    ‚îî‚îÄ‚îÄ summary_pulse_values.sql
‚îú‚îÄ‚îÄ src/
‚îÇ    ‚îî‚îÄ‚îÄ db_dao.py             # Database access object (RemoteLaboratoryDAO)
‚îú‚îÄ‚îÄ lab-manager/              # Flask UI + REST API for experiment/pattern management
‚îÇ    ‚îú‚îÄ‚îÄ plant_config_app.py
‚îÇ    ‚îú‚îÄ‚îÄ templates/
‚îÇ    ‚îî‚îÄ‚îÄ readfiles.py
‚îú‚îÄ‚îÄ collecting_data_opcua_old.py  # [legacy] Script for OPC UA communication
‚îú‚îÄ‚îÄ collecting_profinet.py        # [legacy] Script for Profinet communication
‚îú‚îÄ‚îÄ insert_pulse_train_on_database.py  # Utility to insert custom pulse trains
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md                  # Project documentation (this file)
‚îú‚îÄ‚îÄ .gitignore                 # Files and folders excluded from Git
```

---

## Requirements

- Python 3.9+
- SQLite 3 (j√° incluso no Python) **ou** um servidor MySQL 8.0+
- Python libraries:
  - `snap7`
  - `mysql-connector-python` (somente necess√°rio quando `DB_BACKEND=mysql`)

Install dependencies with:

```bash
pip install python-snap7 mysql-connector-python
```

---

## How It Works

1. The system **connects to a PLC** using the IP, rack, and slot configurations.
2. It **reads a byte** from a specified DB block and **interprets it bit-by-bit**.
3. Whenever a change is detected, it:
   - Converts the bit array into an **integer step**.
   - Saves the data into a `.txt` and `.csv` file.
   - Inserts the step and timestamp into the database.
4. After collection ends, the **pulse train** is automatically **saved into a summary table** for future analysis.

---

## Usage

### Run the main script

```bash
python collecting_profinet.py
```

> (You can adapt this command if using another acquisition script.)

---

### Configuration

Inside the code (`collecting_profinet.py`), you can modify:

- `plc_ip` ‚Üí PLC IP address (e.g., `"192.168.0.10"`)
- `rack`, `slot` ‚Üí PLC hardware configuration
- `db_number`, `byte_index` ‚Üí Memory address to read
- `timeout` ‚Üí Experiment duration (in seconds)

---

### Database Schema

You need to run the SQL scripts inside the `database-scripts/` folder to create the necessary tables:

- `dadoscoletados2`: stores individual pulse data
- `dadoscoletados_summary`: stores full pulse train patterns
- `ground_truth_patterns`: refer√™ncia dos padr√µes do professor para cada experimento (alimentados pela nova UI de gerenciamento)

---

### Database backend selection

`RemoteLaboratoryDAO` agora aceita tanto **MySQL** quanto **SQLite**. A escolha √© feita atrav√©s da vari√°vel de ambiente `DB_BACKEND`:

```bash
# MySQL (padr√£o)
export DB_BACKEND=mysql
export MYSQL_HOST=localhost
export MYSQL_DATABASE=cae_dr
export MYSQL_USER=root
export MYSQL_PASSWORD=secret

# ou SQLite
export DB_BACKEND=sqlite
export SQLITE_DB_PATH=/abs/path/para/remote_lab.sqlite3
```

- Quando `DB_BACKEND=mysql` (valor padr√£o) nada muda em rela√ß√£o ao comportamento antigo; voc√™ s√≥ precisa garantir que o `mysql-connector-python` est√° instalado e que o banco `cae_dr` exista.
- Quando `DB_BACKEND=sqlite`, o arquivo informado em `SQLITE_DB_PATH` √© criado automaticamente (padr√£o: `data/remote_lab.sqlite3`) e todas as consultas passam a usar o driver embutido `sqlite3`.
- Certifique-se de apontar `SQLITE_DB_PATH` para um local com permiss√£o de escrita. Se for um caminho inv√°lido, o DAO volta automaticamente para `data/remote_lab.sqlite3`.

Essa configura√ß√£o vale automaticamente para toda a aplica√ß√£o Flask (`lab-manager/plant_config_app.py`) e para os scripts que utilizam `RemoteLaboratoryDAO`.

---

### Web managers (Flask)

- **Gerenciador de Experimentos** ‚Äì dispon√≠vel em `http://localhost:5000/` ‚Äì lista/cria/edita/exclui registros da tabela `plant_config`.
- **Gerenciador de Padr√µes do Professor** ‚Äì dispon√≠vel em `http://localhost:5000/ground-truth` ‚Äì manipula os dados de `ground_truth_patterns`, permitindo cadastrar os padr√µes vindos do script `patterns_from_professor.sql` diretamente da interface web.

Ambos os m√≥dulos compartilham o mesmo backend (MySQL ou SQLite), ent√£o qualquer altera√ß√£o via UI √© automaticamente refletida no banco correspondente.

---

### REST API

O mesmo aplicativo (`lab-manager/plant_config_app.py`) exp√µe um blueprint JSON em `http://localhost:5000/api`. Principais rotas:

- `GET /api/experiments` / `POST /api/experiments` / `GET|PUT|DELETE /api/experiments/<id>` para listar, criar e administrar entradas em `plant_config`.
- `GET /api/ground-truth` / `POST /api/ground-truth` / `GET|PUT|DELETE /api/ground-truth/<id>` para gerenciar `ground_truth_patterns`.

As rotas executam valida√ß√µes b√°sicas e retornam c√≥digos HTTP apropriados, facilitando a integra√ß√£o com chatbots ou qualquer outro cliente.

---

## Notes

- The generated `.txt` and `.csv` files are saved with automatic **version control** (`v1`, `v2`, etc.).
- The database connection parameters (host, database, user, password) are configured inside the `RemoteLaboratoryDAO` class.
- This project is modular and ready for expansion (for example: adding OPC UA or Profinet acquisitions).

---

## Credits & Attribution

- Original project: [Remote Laboratory ‚Äì PLC Data Acquisition System](https://github.com/RodSalg/remote-laboratory) (rod-salgado and collaborators).  
- UFG capstone adjustments: documentation notes, utility scripts and data structures tailored to the academic context.

---

## Team

- Rodrigo Ferraz Azevedo  
- Guido Machado  
- Marcelo Marcomini

---

## Chatbot (LangChain)

O diret√≥rio `chatbot/` cont√©m um prot√≥tipo de agente que utiliza LangChain + GPT para conversar com os endpoints do `lab-manager`. Para usar:

1. Instale as depend√™ncias: `pip install -r chatbot/requirements.txt`
2. Garanta que o Flask esteja rodando (`python lab-manager/plant_config_app.py`)
3. Exporte `OPENAI_API_KEY` e rode `python -m chatbot.main`

O agente reconhece comandos como ‚Äúlistar experimentos‚Äù, ‚Äúcadastrar padr√£o do professor‚Äù etc., chamando as ferramentas declaradas em `chatbot/tools.py`.

---

## .gitignore

All unnecessary files (such as cache, virtual environments, local settings, etc.) are already excluded from Git tracking.

---

## License

This project is licensed under the [MIT License](LICENSE).
